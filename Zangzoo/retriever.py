# retriever.py
import os, pickle, faiss, threading
from sentence_transformers import SentenceTransformer

_MODEL_NAME  = "jhgan/ko-sbert-nli"          # í•œêµ­ì–´ SBERT
_DB_TXT      = "bias_db.txt"                # 240â€¯ë¬¸ì¥ íŒŒì¼
_IDX_FILE    = "faiss_bias.index"
_SENT_FILE   = "bias_sent.pkl"

# ---- (NEW) lazy-singleton  -------------------------
_SBERT_MODEL = None          # ì „ì—­ ìºì‹œ
_SBERT_LOCK  = threading.Lock()

def _get_sbert():
    """SBERTë¥¼ ë‹¨ 1ë²ˆë§Œ ë©”ëª¨ë¦¬ì— ì˜¬ë¦¼ + warm-up"""
    global _SBERT_MODEL
    if _SBERT_MODEL is None:
        with _SBERT_LOCK:
            if _SBERT_MODEL is None:
                print("ğŸ”§  SBERT ë¡œë”©â€¦")
                _SBERT_MODEL = SentenceTransformer(_MODEL_NAME, device="mps")
                _SBERT_MODEL.encode(["warm-up"], convert_to_tensor=True)
                print("âœ…  SBERT ë¡œë”© ì™„ë£Œ")
    return _SBERT_MODEL
# ----------------------------------------------------


def build_index(db_txt: str = _DB_TXT):
    """bias_db.txt â†’ ì„ë² ë”© â†’ FAISS ì¸ë±ìŠ¤ (*.index / *.pkl) ì €ì¥"""
    sents = [ln.strip() for ln in open(db_txt, encoding="utf-8") if ln.strip()]
    embs  = _get_sbert().encode(
        sents, convert_to_tensor=True, normalize_embeddings=True
    ).cpu().numpy()

    index = faiss.IndexFlatIP(embs.shape[1])
    index.add(embs)
    faiss.write_index(index, _IDX_FILE)
    pickle.dump(sents, open(_SENT_FILE, "wb"))
    print(f"âœ…  Bias DB indexed: {len(sents)} ë¬¸ì¥")

def get_relevant(query: str, k: int = 2):
    """query â†’ Top-k ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸"""
    if not os.path.exists(_IDX_FILE):
        build_index()
    index  = faiss.read_index(_IDX_FILE)
    sents  = pickle.load(open(_SENT_FILE, "rb"))
    qvec   = _get_sbert().encode(
        [query], convert_to_tensor=True, normalize_embeddings=True
    ).cpu().numpy()
    _, idx = index.search(qvec, k)
    return [sents[i] for i in idx[0]]